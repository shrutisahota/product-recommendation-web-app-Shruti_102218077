{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Model Training Notebook\n", "Train components: text embeddings + clustering (NLP) and a CV classifier skeleton."]}, {"cell_type": "code", "metadata": {}, "source": ["import pandas as pd, numpy as np\n", "csv_path = '/content/data/products.csv'\n", "df = pd.read_csv(csv_path)\n", "df['text_blob'] = (df.get('title','').fillna('') + ' | ' + df.get('brand','').fillna('') + ' | ' + df.get('description','').fillna(''))\n", "len(df)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Sentence-Transformers embeddings"]}, {"cell_type": "code", "metadata": {}, "source": ["from sentence_transformers import SentenceTransformer\n", "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n", "X = model.encode(df['text_blob'].fillna('')).astype('float32')\n", "X.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## KMeans clustering"]}, {"cell_type": "code", "metadata": {}, "source": ["from sklearn.cluster import KMeans\n", "k=8\n", "km = KMeans(n_clusters=k, n_init=10, random_state=42)\n", "labels = km.fit_predict(X)\n", "df['cluster']=labels\n", "df['cluster'].value_counts()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## CV Training (Transfer Learning Skeleton)"]}, {"cell_type": "code", "metadata": {}, "source": ["import torch, torch.nn as nn\n", "from torchvision import models, transforms\n", "from torch.utils.data import Dataset, DataLoader\n", "from PIL import Image\n", "import requests, io\n", "LABELS = ['chair','table','sofa','bed','cabinet','lamp','shelf','stool','bench','desk']\n", "label_to_idx = {l:i for i,l in enumerate(LABELS)}\n", "class URLImageDataset(Dataset):\n", "    def __init__(self, df, transform=None):\n", "        self.df = df.reset_index(drop=True)\n", "        self.t = transform\n", "    def __len__(self): return len(self.df)\n", "    def __getitem__(self, i):\n", "        row = self.df.iloc[i]\n", "        url = str(row.get('images','')).split(',')[0].strip()\n", "        lab = 0\n", "        title = (row.get('title') or '') + ' ' + (row.get('categories') or '')\n", "        for j,l in enumerate(LABELS):\n", "            if l in title.lower(): lab=j; break\n", "        try:\n", "            img_bytes = requests.get(url, timeout=10).content\n", "            img = Image.open(io.BytesIO(img_bytes)).convert('RGB')\n", "        except Exception:\n", "            img = Image.new('RGB',(224,224),(200,200,200))\n", "        if self.t: img = self.t(img)\n", "        return img, lab\n", "transform = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()])\n", "ds = URLImageDataset(df.sample(min(500, len(df))), transform)\n", "dl = DataLoader(ds, batch_size=8, shuffle=True)\n", "model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n", "model.fc = nn.Linear(model.fc.in_features, len(LABELS))\n", "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n", "model.to(device)\n", "opt = torch.optim.Adam(model.parameters(), lr=1e-4)\n", "crit = nn.CrossEntropyLoss()\n", "for epoch in range(1):\n", "    model.train()\n", "    total=0; correct=0\n", "    for x,y in dl:\n", "        x,y = x.to(device), y.to(device)\n", "        opt.zero_grad(); out = model(x); loss = crit(out,y); loss.backward(); opt.step()\n", "        pred = out.argmax(1); total+=y.size(0); correct += (pred==y).sum().item()\n", "    print('epoch', epoch, 'train acc', correct/total)\n", "import os\n", "os.makedirs('/content/models', exist_ok=True)\n", "torch.jit.save(torch.jit.script(model.cpu()), '/content/models/cv.pt')\n", "print('Saved TorchScript to /content/models/cv.pt')"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 5}